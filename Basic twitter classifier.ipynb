{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic twitter classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urlRatio(user,tweets):\n",
    "    count_url = 0\n",
    "    count_tweet = 0\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        count_url += len(tweet['entities']['urls'])\n",
    "        count_tweet += 1\n",
    "        \n",
    "    return count_url/count_tweet * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffRatio(user):\n",
    "    if(user['followers_count']!=0):\n",
    "        return user['friends_count']/user['followers_count']\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verified(user):\n",
    "    return int(user['verified'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def created(user):\n",
    "    time_seconds = datetime.strptime(user['created_at'],'%a %b %d %H:%M:%S %z %Y').timestamp()\n",
    "    if time_seconds > 1571090400 and time_seconds < 1573340400:\n",
    "        return 100.0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtagRatio(user,tweets):\n",
    "    count_hashtag = 0\n",
    "    count_tweet = 0\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        count_hashtag += len(tweet['entities']['hashtags'])\n",
    "        count_tweet += 1\n",
    "        \n",
    "    return count_hashtag/count_tweet * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentionsRatio(user,tweets):\n",
    "    count_mentions = 0\n",
    "    count_tweet = 0\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        count_mentions += len(tweet['entities']['user_mentions'])\n",
    "        count_tweet += 1\n",
    "        \n",
    "    return count_mentions/count_tweet * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxTweetsHour(user,tweets):\n",
    "    hourlyTweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        time_seconds = datetime.strptime(tweet['created_at'],'%a %b %d %H:%M:%S %z %Y').timestamp()\n",
    "        hourlyTweets.append(time_seconds)\n",
    "        \n",
    "    tmp_counter = 0\n",
    "    max_counter = 0\n",
    "    last_hour = 0\n",
    "    for i in range(len(hourlyTweets)-1):\n",
    "        tmp_counter += 1 \n",
    "        if((hourlyTweets[last_hour]+3600)<hourlyTweets[i+1]):\n",
    "            max_counter = max(max_counter,tmp_counter)\n",
    "            tmp_counter = 0\n",
    "            last_hour = i + 1\n",
    "\n",
    "    return max_counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retweetCount(user,tweets):\n",
    "    retweet_count = 0\n",
    "    count_tweet = 0\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        retweet_count += tweet['retweet_count']\n",
    "        count_tweet += 1\n",
    "        \n",
    "    return retweet_count/count_tweet * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accountPropertiesComponent(users):\n",
    "    user_properties = []\n",
    "    for user in users:\n",
    "        \n",
    "        tweets = list(db_test.tweets.find({'id_user' : user['id_str']}).limit(300).rewind())\n",
    "\n",
    "        R1 = urlRatio(user,tweets)\n",
    "        R2 = ffRatio(user)\n",
    "        R3 = verified(user)\n",
    "        R4 = created(user)\n",
    "        R5 = hashtagRatio(user,tweets)\n",
    "        R6 = mentionsRatio(user,tweets)\n",
    "        R7 = maxTweetsHour(user,tweets)\n",
    "        R8 = retweetCount(user,tweets)\n",
    "        \n",
    "        results = {\"id_user\": user['id_str'], \"urlRatio\": R1, \"friendFollowers\" : R2, \"verified\" : R3, \"created\" : R4, \"hashtagRatio\" : R5, \"mentionsRatio\" : R6, \"MaxTweetsHour\" : R7, 'retweetCountRatio':R8 }\n",
    "        db_test.results.update_one({'id_str':results['id_user']},{\"$set\": results},upsert=True)\n",
    "        user_properties.append(results)\n",
    "    return user_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------\n",
    "#    Title: <title of program/source code>\n",
    "#    Author: enzo-santos\n",
    "#    Date: 3 may 2020\n",
    "#    Availability: https://gist.github.com/DustinAlandzes/a835909ffd15b9927820d175a48dee41#gistcomment-3285038\n",
    "#\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "def ApEn_new(U, m, r):\n",
    "    U = np.array(U)\n",
    "    N = U.shape[0]\n",
    "            \n",
    "    def _phi(m):\n",
    "        z = N - m + 1.0\n",
    "        x = np.array([U[i:i+m] for i in range(int(z))])\n",
    "        X = np.repeat(x[:, np.newaxis], 1, axis=2)\n",
    "        C = np.sum(np.absolute(x - X).max(axis=2) <= r, axis=0) / z\n",
    "        return np.log(C).sum() / z\n",
    "    \n",
    "    return abs(_phi(m + 1) - _phi(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meassureEntropyOne(user):\n",
    "    timestamps = db_test.tweets.find({'id_user' : user['id_str']},{'created_at':1})\n",
    "    hourlyTweets = []\n",
    "    for time in timestamps:\n",
    "        time_seconds = datetime.strptime(time['created_at'],'%a %b %d %H:%M:%S %z %Y').timestamp()\n",
    "        hourlyTweets.append(time_seconds)\n",
    "\n",
    "    #segmentSize = 3600 #3600 #86400\n",
    "    segmentNumber = 100\n",
    "    segmentSize = int((max(hourlyTweets)-min(hourlyTweets)))/segmentNumber\n",
    "    segmentList = [0]*(segmentNumber+1)\n",
    "    minHT = min(hourlyTweets)\n",
    "    \n",
    "    for time in hourlyTweets:\n",
    "        diference = time-minHT\n",
    "        segment = int(diference/segmentSize)\n",
    "        segmentList[segment] += 1\n",
    "        \n",
    "    return {\"id_user\": user['id_str'], \"entropy\": ApEn_new(segmentList, 7, 0.3 * np.std(segmentList))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meassureEntropyAll(users):\n",
    "    users_entropy = []\n",
    "    for user in users:\n",
    "        results = meassureEntropyOne(user)\n",
    "        users_entropy.append(results)\n",
    "        db_test.results.update_one({'id_str':results['id_user']},{\"$set\": results},upsert=True)\n",
    "    return users_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam/Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTweetsTrain(users):\n",
    "    tweets_final = []\n",
    "    for user in users:\n",
    "        tweets = db_train.tweets.find({'id_user' : user['id_str']},{'text':1,})\n",
    "        for tweet in tweets:\n",
    "            label = user['label']\n",
    "            tweet = tweet['text']\n",
    "            tweets_final.append([label,tweet])\n",
    "    return pd.DataFrame(tweets_final, columns =['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTweetsTest(user):\n",
    "    tweets_final = []\n",
    "    tweets = db_test.tweets.find({'id_user' : user['id_str']},{'text':1,})\n",
    "    for tweet in tweets:\n",
    "        tweet = tweet['text']\n",
    "        tweets_final.append(['',tweet])\n",
    "    return pd.DataFrame(tweets_final, columns =['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spamDetectionOne(user,tweets_test,tweets_train,bow_transformer,tfidf_transformer,spam_detect_model):\n",
    "    bow = bow_transformer.transform(tweets_test['message'])\n",
    "    m_tfidf = tfidf_transformer.transform(bow)\n",
    "    prediction = spam_detect_model.predict(m_tfidf).tolist()\n",
    "     \n",
    "    return {\"id_user\": user['id_str'], \"spam\": 100*prediction.count(\"bot\")/len(prediction)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spamDetectionAll(test_users, train_users):\n",
    "    user_spam = []\n",
    "    tweets_train = prepareTweetsTrain(train_users)\n",
    "    \n",
    "    bow_transformer = CountVectorizer().fit(tweets_train['message'])\n",
    "    train_bow = bow_transformer.transform(tweets_train['message'])\n",
    "    \n",
    "    tfidf_transformer = TfidfTransformer().fit(train_bow)\n",
    "    train_tfidf = tfidf_transformer.transform(train_bow)\n",
    "    \n",
    "    spam_detect_model = MultinomialNB().fit(train_tfidf,tweets_train['label'])\n",
    "    \n",
    "    for user_test in test_users:\n",
    "        tweets_test = prepareTweetsTest(user_test)\n",
    "        results = spamDetectionOne(user_test,tweets_test,tweets_train,bow_transformer,tfidf_transformer,spam_detect_model)\n",
    "        user_spam.append(results)\n",
    "        db_test.results.update_one({'id_str':results['id_user']},{'$set':results},upsert=True)\n",
    "    return user_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def botClassifier(df_test,df_train,train_labels):\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, random_state = 1)\n",
    "    rf.fit(df_train, train_labels);\n",
    "    predictions = rf.predict(df_test)\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(predictions)-1):\n",
    "        results.append({'id_str':test_users_results[i]['id_user'],'label':predictions[i]})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "def dict_merger(d1,d2,d3, keyname):\n",
    "    d4 = defaultdict(dict)\n",
    "\n",
    "    for elem in d1: \n",
    "        d4[elem[keyname]].update(elem) \n",
    "\n",
    "    for elem in d2:\n",
    "        d4[elem[keyname]].update(elem)\n",
    "\n",
    "    for elem in d3: \n",
    "        d4[elem[keyname]].update(elem)\n",
    "\n",
    "    return d4.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_db(df):\n",
    "    labels = 0\n",
    "    if('label' in df.columns):\n",
    "        labels = np.array(df_train['label'])\n",
    "\n",
    "    df = df.drop('label', axis=1, errors='ignore')\n",
    "    df = df.drop('id_str', axis=1, errors='ignore')\n",
    "    df = df.drop('id_user', axis=1, errors='ignore')\n",
    "    df = df.drop('_id', axis=1, errors='ignore')\n",
    "\n",
    "    return df, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pymongo import IndexModel, ASCENDING, DESCENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'user'\n",
    "password = 'password'\n",
    "\n",
    "url = 'mongodb://'+username+':'+password+'@127.0.0.1/twitterEN'\n",
    "client1 = MongoClient(url)\n",
    "client2 = MongoClient(url)\n",
    "\n",
    "db_train = client1.twitterEN\n",
    "db_test = client2.twitterESP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = list(db_train.users.find({}))\n",
    "test_users = list(db_test.users.find({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Users Feactures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_property = accountPropertiesComponent(test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_entropy = meassureEntropyAll(test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_spam = spamDetectionAll(test_users,train_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = db_test.users.find({})\n",
    "user_attributes = dict_merger(user_entropy,user_spam,user_property, 'id_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Bots Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users_results = list(db_train.results.find({}))\n",
    "test_users_results = list(db_test.results.find({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_users_results)\n",
    "df_test = pd.DataFrame(test_users_results) # pd.DataFrame(user_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, train_labels = set_db(df_train)\n",
    "df_test, test_labels = set_db(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = botClassifier(df_test,df_train,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bots = []\n",
    "list_humans = []\n",
    "for item in results:\n",
    "    if item['label'] == 'bot':\n",
    "        list_bots.append(item)\n",
    "    else:\n",
    "        list_humans.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_bots)/len(results)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
